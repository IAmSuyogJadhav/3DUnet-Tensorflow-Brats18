{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Step-Counting.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "54Lt_YdXaCLf",
        "0Esp93WWEvkf",
        "Gasf7MweEzSX"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IAmSuyogJadhav/3DUnet-Tensorflow-Brats18/blob/master/Step_Counting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBF5LVDfDkPs",
        "colab_type": "code",
        "outputId": "9dcb0117-edbb-4f3b-c35e-aed27769ef4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Sep  7 17:05:38 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 430.40       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8    28W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzTUr9OKDhbI",
        "colab_type": "text"
      },
      "source": [
        "# Colab Stuff"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PuCvqj7DTtt",
        "colab_type": "code",
        "outputId": "7d5348c3-eb7d-47e8-997a-9018e8ec1406",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BV2yQGyECUo",
        "colab_type": "code",
        "outputId": "5e87f788-d89e-4889-a33a-dcc6c994f327",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        }
      },
      "source": [
        "!7z x '/gdrive/My Drive/Step-Counting/PedometerDataset-cleaned.zip'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,4 CPUs Intel(R) Xeon(R) CPU @ 2.30GHz (306F0),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan /gdrive/My Drive/Step-Counting/\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1 file, 192198211 bytes (184 MiB)\n",
            "\n",
            "Extracting archive: /gdrive/My Drive/Step-Counting/PedometerDataset-cleaned.zip\n",
            "--\n",
            "Path = /gdrive/My Drive/Step-Counting/PedometerDataset-cleaned.zip\n",
            "Type = zip\n",
            "Physical Size = 192198211\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b  2% 15 - data/P016/Regular/Hip.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  4% 28 - data/P015/SemiRegular/Hip.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                       \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  7% 43 - data/P024/Unstructured/Wrist.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  9% 60 - data/P008/Unstructured/Hip.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 13% 76 - data/P008/Regular/Ankle.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 16% 98 - data/P009/Unstructured/Hip.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 19% 117 - data/P017/Unstructured/Hip.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 22% 131 - data/P017/Regular/Wrist.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                      \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 25% 150 - data/P013/Regular/Wrist.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                      \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 29% 165 - data/P030/SemiRegular/Ankle.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 33% 185 - data/P007/SemiRegular/Ankle.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 36% 206 - data/P014/Regular/Hip.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 40% 229 - data/P010/Regular/Ankle.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                      \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 44% 251 - data/P012/Unstructured/Hip.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 47% 272 - data/P006/Unstructured/Wrist.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 51% 295 - data/P021/SemiRegular/Hip.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 55% 318 - data/P020/SemiRegular/Ankle.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 58% 333 - data/P028/SemiRegular/Hip.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 62% 350 - data/P027/Unstructured/Ankle.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 65% 374 - data/P002/SemiRegular/Wrist.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 69% 395 - data/P018/SemiRegular/Ankle.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 72% 414 - data/P029/SemiRegular/Ankle.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 76% 437 - data/P003/Regular/Wrist.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                      \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 80% 461 - data/P025/Unstructured/Hip.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 83% 482 - data/P026/Unstructured/Wrist.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 87% 501 - data/P023/Unstructured/Wrist.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 91% 520 - data/P004/Unstructured/Wrist.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 95% 543 - data/P001/SemiRegular/Hip.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 98% 564 - data/P005/SemiRegular/Wrist.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEverything is Ok\n",
            "\n",
            "Folders: 121\n",
            "Files: 452\n",
            "Size:       589743402\n",
            "Compressed: 192198211\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pU2KXGNFEDG6",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmGao65FQsSq",
        "colab_type": "code",
        "outputId": "32e9e766-0af4-494f-8671-a59826efbe88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# For better CUDA-related errors\n",
        "%env CUDA_LAUNCH_BLOCKING=1\n",
        "\n",
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import deque\n",
        "import torch \n",
        "from torch import nn\n",
        "from torchsummary import summary\n",
        "from sklearn.metrics import f1_score\n",
        "from collections.abc import Iterable\n",
        "import shutil"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: CUDA_LAUNCH_BLOCKING=1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuYc7sPmnfry",
        "colab_type": "text"
      },
      "source": [
        "# Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXDKN4aLIW7k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_data_folder(folder, to_read='Wrist'):\n",
        "    \"\"\"\n",
        "    read_data_folder(folder, to_read='Wrist')\n",
        "    -----------------\n",
        "    Designed to work on Pedometer Evaluation Project Dataset.\n",
        "    Reads the data and corresponding labels from a single subfolder of the\n",
        "    dataset.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    `folder`: string, required\n",
        "        The folder having at least these two files: {to_read}.csv and\n",
        "        steps.txt.\n",
        "    `to_read`: string, optional\n",
        "        Indicates which data is to be read. Defaults to \"Wrist\". Can be one of\n",
        "        ['Wrist', 'Hip', 'Ankle']\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    `data`: pandas.DataFrame object\n",
        "         The data loaded from the given subfolder, along with the labels in a\n",
        "         single DataFrame object. Shape: (n, 20), n is variable.\n",
        "    \"\"\"\n",
        "\n",
        "    assert to_read in ['Wrist', 'Hip', 'Ankle'], \\\n",
        "        \"to_read must be one of ['Wrist', 'Hip', 'Ankle']\"\n",
        "    data = pd.read_csv(\n",
        "        os.path.join(folder, f'{to_read}.csv'), skiprows=[0, 2], delimiter='\\t'\n",
        "        )\n",
        "    data['gap'] = 0\n",
        "    data['gap'][1:] = (\n",
        "        data.Timestamp.values[1:] - data.Timestamp.values[:-1]\n",
        "        ).astype(np.int)\n",
        "\n",
        "    # Read the labels file\n",
        "    label = pd.read_csv(\n",
        "        os.path.join(folder, 'steps.txt'),\n",
        "        delim_whitespace=True, names=['t', 'move']\n",
        "        )\n",
        "    \n",
        "    # Ignoring shifts for now.\n",
        "    mask = label.t[label.move.str[1:] != 'shift']\n",
        "\n",
        "    # Convert the labels to one-hot format and add to the data\n",
        "    data['label'] = np.zeros(len(data), dtype=int)\n",
        "    data['label'][mask] = 1\n",
        "\n",
        "    # Check for large gaps and ignore all the values after them.\n",
        "    if len(data.index[data.gap > 133]):\n",
        "        data.drop(\n",
        "            range(data.index[data.gap > 133][0], len(data)),\n",
        "            axis=0, inplace=True\n",
        "            )\n",
        "    return data\n",
        "\n",
        "\n",
        "def read_data(data_path, to_read='Wrist'):\n",
        "    \"\"\"\n",
        "    read_data(folder, to_read='Wrist')\n",
        "    -----------------\n",
        "    Designed to work on Pedometer Evaluation Project Dataset.\n",
        "    Reads the data and corresponding labels from a all the subfolders of the\n",
        "    dataset.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    `folder`: string, required\n",
        "        The folder containing the data folders, each of which contains 3\n",
        "         subfolders: Regular, SemiRegular and Unstructured, each having at\n",
        "          least these two files: {to_read}.csv and steps.txt.\n",
        "    `to_read`: string, optional\n",
        "        Indicates which data is to be read. Defaults to \"Wrist\". Can be one of\n",
        "        ['Wrist', 'Hip', 'Ankle']\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    `data`: list\n",
        "        A list of pandas.DataFrame objects generated by reading all the\n",
        "        training examples (and their labels) in the dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    assert to_read in ['Wrist', 'Hip', 'Ankle'], \\\n",
        "        \"to_read must be one of ['Wrist', 'Hip', 'Ankle']\"\n",
        "\n",
        "    data = []\n",
        "\n",
        "    # Gather a list of all the subfolders\n",
        "    subfolders = [f[1] for f in os.walk(data_path)][0]\n",
        "\n",
        "    # Just needed for the progress bar\n",
        "    total = len(subfolders)\n",
        "    step = 25 / total\n",
        "    for i, sub in enumerate(subfolders):\n",
        "        # Each subfolder has these 3 directories\n",
        "        for sub2 in ['Regular', 'SemiRegular', 'Unstructured']:\n",
        "            d = read_data_folder(os.path.join(data_path, sub, sub2), to_read)\n",
        "            data.append(d)\n",
        "\n",
        "        # Print the progress bar\n",
        "        print(\n",
        "            '\\r' + f'Progress: '\n",
        "            f\"[{'=' * int((i+1) * step) + ' ' * (24 - int((i + 1) * step))}]\"\n",
        "            f\"({math.ceil((i+1) * 100 / (total))} %)\",\n",
        "            end=''\n",
        "            )\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "def generate_data(\n",
        "    data, window=32,\n",
        "    features=[\n",
        "        'QuatW', 'QuatX', 'QuatY', 'QuatZ', 'GyroX', 'GyroY', 'GyroZ',\n",
        "        'AccelX', 'AccelY', 'AccelZ', 'MagX', 'MagY', 'MagZ'\n",
        "            ]):\n",
        "    \"\"\"\n",
        "    generate_data(data, window=32, features=['QuatW', QuatX...)\n",
        "    -----------------------------------------------------------\n",
        "    Designed to work on Pedometer Evaluation Project Dataset.\n",
        "    Takes as input the data loaded from the dataset using the `read_data`\n",
        "    function and gives as output the numpy array generated by reading only the\n",
        "    selected features from the dataset and using specified window size.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    `data`: list, required\n",
        "        A list of pandas.DataFrame objects generated by calling the `read_data`\n",
        "        function on the dataset.\n",
        "    `window`: int, optional\n",
        "        No. of readings to put in a single training example. Defaults to 32.\n",
        "    `features`: list, optional\n",
        "        List of features from the training data to be used. Defaults to all of\n",
        "        them being used (['QuatW', 'QuatX', 'QuatY', 'QuatZ', 'GyroX', 'GyroY',\n",
        "        'GyroZ', 'AccelX', 'AccelY', 'AccelZ', 'MagX', 'MagY', 'MagZ]).\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    `dat`: numpy.array object\n",
        "        All the data loaded according to given specifications, in a single\n",
        "        numpy array. Shape: (n, window, n_f), n is the total no. of windows\n",
        "        that could be generated, n_f is the length of `features` list.\n",
        "    `lbl`: numpy.array object\n",
        "        One-hot encoded labels corresponding to the data. Shape: (n, window),\n",
        "        n is the total no. of windows that could be generated.\n",
        "    \"\"\"\n",
        "    dat = []  # To store the data\n",
        "    lbl = []  # To store the labels\n",
        "\n",
        "    # For progress bar\n",
        "    total = len(data)\n",
        "    step = 25 / total\n",
        "    for i, df in enumerate(data):\n",
        "        for j in range(len(df) // window):\n",
        "\n",
        "            # 1 is subtracted from the end index, because pandas loc includes\n",
        "            # the end index while slicing\n",
        "            dat.append(\n",
        "                df.loc[j * window: (j + 1) * window - 1, features].values)\n",
        "            lbl.append(\n",
        "                df.loc[j * window: (j + 1) * window - 1, 'label'].values)\n",
        "\n",
        "        # Print Progress Bar\n",
        "        print(\n",
        "            '\\r' + f'Progress: '\n",
        "            f\"[{'=' * int((i+1) * step) + ' ' * (24 - int((i+1) * step))}]\"\n",
        "            f\"({math.ceil((i+1) * 100 / (total))} %)\",\n",
        "            end='')\n",
        "\n",
        "    dat = np.array(dat)\n",
        "    lbl = np.array(lbl)\n",
        "    return dat, lbl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nF4pTznNngzK",
        "colab_type": "code",
        "outputId": "6ac1e5b1-bf9a-4cd4-d832-eb52b8f08547",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        }
      },
      "source": [
        "#@title Set options\n",
        "window = 76 #@param\n",
        "\n",
        "features = [\n",
        "    'QuatW', 'QuatX', 'QuatY', 'QuatZ',\n",
        "    'GyroX', 'GyroY', 'GyroZ',\n",
        "    # 'AccelX', 'AccelY', 'AccelZ',\n",
        "    'MagX', 'MagY', 'MagZ'\n",
        "        ]\n",
        "input_size = len(features)\n",
        "print(\"Reading Data...\\n\")\n",
        "data = read_data('/content/data/')\n",
        "print('\\nDone!\\n')\n",
        "print(f\"Generating Data with window size of {window}...\\n\")\n",
        "X, y = generate_data(data, window=window, features=features)\n",
        "print('\\nDone!\\n')\n",
        "print('*'*20)\n",
        "print(f'Data shape: {X.shape}')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading Data...\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:45: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Progress: [=========================](100 %)\n",
            "Done!\n",
            "\n",
            "Generating Data with window size of 76...\n",
            "\n",
            "Progress: [=========================](100 %)\n",
            "Done!\n",
            "\n",
            "********************\n",
            "Data shape: (12482, 76, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xl275Ye22ooT",
        "colab_type": "code",
        "outputId": "d085ae4d-97a3-4f18-abc8-7887ac2ae1ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "split = 0.8\n",
        "n = len(X)\n",
        "\n",
        "is_cuda = torch.cuda.is_available()\n",
        "\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU is available\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available, CPU used\")\n",
        "\n",
        "\n",
        "X_train = X[:int(split * n), ...].astype(np.float32)\n",
        "y_train = y[:int(split * n), ...].astype(np.float32)\n",
        "X_val = X[int(split * n):, ...].astype(np.float32)\n",
        "y_val = y[int(split * n):, ...].astype(np.float32)\n",
        "\n",
        "y_train = torch.from_numpy(y_train).to(device)\n",
        "X_train = torch.from_numpy(X_train).to(device)\n",
        "y_val = torch.from_numpy(y_val).to(device)\n",
        "X_val = torch.from_numpy(X_val).to(device)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU is available\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCJopTTT9zBN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Testing\n",
        "# X_bak = X.copy()\n",
        "# y_bak = y.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJYqB0QcKWRl",
        "colab_type": "text"
      },
      "source": [
        "# Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ByoTKmadIrDf",
        "colab": {}
      },
      "source": [
        "# def pretty_size(size):\n",
        "# \t\"\"\"Pretty prints a torch.Size object\"\"\"\n",
        "# \tassert(isinstance(size, torch.Size))\n",
        "# \treturn \" × \".join(map(str, size))\n",
        "\n",
        "# def dump_tensors(gpu_only=True):\n",
        "# \t\"\"\"Prints a list of the Tensors being tracked by the garbage collector.\"\"\"\n",
        "# \timport gc\n",
        "# \ttotal_size = 0\n",
        "# \tfor obj in gc.get_objects():\n",
        "# \t\ttry:\n",
        "# \t\t\tif torch.is_tensor(obj):\n",
        "# \t\t\t\tif not gpu_only or obj.is_cuda:\n",
        "# \t\t\t\t\tprint(\"%s:%s%s %s\" % (type(obj).__name__, \n",
        "# \t\t\t\t\t\t\t\t\t\t  \" GPU\" if obj.is_cuda else \"\",\n",
        "# \t\t\t\t\t\t\t\t\t\t  \" pinned\" if obj.is_pinned else \"\",\n",
        "# \t\t\t\t\t\t\t\t\t\t  pretty_size(obj.size())))\n",
        "# \t\t\t\t\ttotal_size += obj.numel()\n",
        "# \t\t\telif hasattr(obj, \"data\") and torch.is_tensor(obj.data):\n",
        "# \t\t\t\tif not gpu_only or obj.is_cuda:\n",
        "# \t\t\t\t\tprint(\"%s → %s:%s%s%s%s %s\" % (type(obj).__name__, \n",
        "# \t\t\t\t\t\t\t\t\t\t\t\t   type(obj.data).__name__, \n",
        "# \t\t\t\t\t\t\t\t\t\t\t\t   \" GPU\" if obj.is_cuda else \"\",\n",
        "# \t\t\t\t\t\t\t\t\t\t\t\t   \" pinned\" if obj.data.is_pinned else \"\",\n",
        "# \t\t\t\t\t\t\t\t\t\t\t\t   \" grad\" if obj.requires_grad else \"\", \n",
        "# \t\t\t\t\t\t\t\t\t\t\t\t   \" volatile\" if obj.volatile else \"\",\n",
        "# \t\t\t\t\t\t\t\t\t\t\t\t   pretty_size(obj.data.size())))\n",
        "# \t\t\t\t\ttotal_size += obj.data.numel()\n",
        "# \t\texcept Exception as e:\n",
        "# \t\t\tpass        \n",
        "# \tprint(\"Total size:\", total_size)\n",
        "\n",
        "# def pretty_size(size):\n",
        "# \t\"\"\"Pretty prints a torch.Size object\"\"\"\n",
        "# \tassert(isinstance(size, torch.Size))\n",
        "# \treturn \" × \".join(map(str, size))\n",
        "\n",
        "# def dump_tensors(gpu_only=True):\n",
        "# \t\"\"\"Prints a list of the Tensors being tracked by the garbage collector.\"\"\"\n",
        "# \timport gc\n",
        "# \ttotal_size = 0\n",
        "# \tfor obj in gc.get_objects():\n",
        "# \t\ttry:\n",
        "# \t\t\tif torch.is_tensor(obj):\n",
        "# \t\t\t\tif not gpu_only or obj.is_cuda:\n",
        "# \t\t\t\t\tprint(\"%s:%s%s %s\" % (type(obj).__name__, \n",
        "# \t\t\t\t\t\t\t\t\t\t  \" GPU\" if obj.is_cuda else \"\",\n",
        "# \t\t\t\t\t\t\t\t\t\t  \" pinned\" if obj.is_pinned else \"\",\n",
        "# \t\t\t\t\t\t\t\t\t\t  pretty_size(obj.size())))\n",
        "# \t\t\t\t\ttotal_size += obj.numel()\n",
        "# \t\t\telif hasattr(obj, \"data\") and torch.is_tensor(obj.data):\n",
        "# \t\t\t\tif not gpu_only or obj.is_cuda:\n",
        "# \t\t\t\t\tprint(\"%s → %s:%s%s%s%s %s\" % (type(obj).__name__, \n",
        "# \t\t\t\t\t\t\t\t\t\t\t\t   type(obj.data).__name__, \n",
        "# \t\t\t\t\t\t\t\t\t\t\t\t   \" GPU\" if obj.is_cuda else \"\",\n",
        "# \t\t\t\t\t\t\t\t\t\t\t\t   \" pinned\" if obj.data.is_pinned else \"\",\n",
        "# \t\t\t\t\t\t\t\t\t\t\t\t   \" grad\" if obj.requires_grad else \"\", \n",
        "# \t\t\t\t\t\t\t\t\t\t\t\t   \" volatile\" if obj.volatile else \"\",\n",
        "# \t\t\t\t\t\t\t\t\t\t\t\t   pretty_size(obj.data.size())))\n",
        "# \t\t\t\t\ttotal_size += obj.data.numel()\n",
        "# \t\texcept Exception as e:\n",
        "# \t\t\tpass        \n",
        "# \tprint(\"Total size:\", total_size)\n",
        "# \n",
        "# \n",
        "# def re_init_weights(m):        \n",
        "#         torch.nn.init.xavier_uniform(m.weight)\n",
        "#         m.bias.data.fill_(0.01)\n",
        "# def save_checkpoint(state, is_best, filename):\n",
        "#     \"\"\"Save checkpoint if a new best is achieved\"\"\"\n",
        "#     if is_best:\n",
        "#         # print (\"=> Saving a new best\")\n",
        "#         torch.save(state, filename)  # save checkpoint\n",
        "#     else:\n",
        "#         # print (\"=> Validation Accuracy did not improve\")\n",
        "#         pass\n",
        "# \n",
        "# \n",
        "def get_last_state(models_dir, model_prefix='Model'):\n",
        "    r\"\"\"\n",
        "    Gives out the path to the last model and its epoch number.\n",
        "    Expect models to be named as (regex): {model}-.*Epoch-\\d*\\.h5\n",
        "    where {model} is the prefix of your model checkpoints, defaults to \"Model\".\n",
        "    \"\"\"\n",
        "    path = os.path.join(models_dir, f\"{model_prefix}-*.\")\n",
        "    models = glob.glob(path)\n",
        "\n",
        "    re_escape = ['(', ')', '.']\n",
        "    for ch in re_escape:\n",
        "        model_prefix = model_prefix.replace(ch, '\\\\' + ch)\n",
        "    \n",
        "    if models:\n",
        "        pat = re.compile(f'.*/{model_prefix}-.*Epoch(\\\\d*)\\\\.pth')\n",
        "        last_model = sorted(models, reverse=True, key=lambda m: int(pat.findall(m)[0]))[0]\n",
        "        epoch = int(pat.findall(last_model)[0])\n",
        "        print(f\"Found last model at:{last_model}\\nEpoch no.: {epoch}\")\n",
        "        return last_model, epoch\n",
        "    else:\n",
        "        print(f\"No model found matching {path}\")\n",
        "        return None, 0\n",
        "\n",
        "\n",
        "def weights_init(m):\n",
        "    try:\n",
        "        nn.init.xavier_uniform(m.weight.data)\n",
        "        nn.init.xavier_uniform(m.bias.data)\n",
        "    except AttributeError:\n",
        "        print(AttributeError(m))\n",
        "\n",
        "\n",
        "def weighted_binary_cross_entropy(output, target, weights=[0.94, 0.06]):\n",
        "        \n",
        "    if weights is not None:\n",
        "        assert len(weights) == 2\n",
        "        \n",
        "        loss = weights[1] * (target * torch.log(output)) + \\\n",
        "               weights[0] * ((1 - target) * torch.log(1 - output))\n",
        "    else:\n",
        "        loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)\n",
        "\n",
        "    return torch.neg(torch.mean(loss))\n",
        "\n",
        "\n",
        "def f1_loss(y_true, y_pred, eps=1e-10):\n",
        "    \n",
        "    tp = torch.sum((y_true*y_pred).to(torch.float), dim=0)\n",
        "    tn = torch.sum(((1-y_true)*(1-y_pred)).to(torch.float), dim=0)\n",
        "    fp = torch.sum(((1-y_true)*y_pred).to(torch.float), dim=0)\n",
        "    fn = torch.sum((y_true*(1-y_pred)).to(torch.float), dim=0)\n",
        "\n",
        "    p = tp / (tp + fp + eps)\n",
        "    r = tp / (tp + fn + eps)\n",
        "\n",
        "    f1 = 2 * p * r / (p + r + eps)\n",
        "    f1 = torch.where(torch.isnan(f1), torch.zeros_like(f1), f1)\n",
        "    return 1 - torch.mean(f1)\n",
        "\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.contiguous().view(input.shape[0], -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S98kKNxE2lQg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Master(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Master, self).__init__()\n",
        "        self.model = 's'\n",
        "        self.compare_fn = None\n",
        "        self.epoch = None\n",
        "        self.mse = nn.MSELoss()\n",
        "        self.epochs_since_ckpt = 0\n",
        "\n",
        "\n",
        "        # Must be defined by the child class\n",
        "        self.init_args = None\n",
        "        self.optimizer = None\n",
        "        self.deq = None\n",
        "\n",
        "    def checkpoint(self, monitor_value, save_name, save_best_only=True):\n",
        "\n",
        "        # Check if we should save the checkpoint\n",
        "        save_ckpt = self.compare_fn(monitor_value)\n",
        "\n",
        "        if save_ckpt or not save_best_only:\n",
        "            ckpt = {'model': self.__class__(*self.init_args),\n",
        "                    'state_dict': self.state_dict(),\n",
        "                    'optimizer' : self.optimizer.state_dict(),\n",
        "                    'epoch': self.epoch\n",
        "                    }\n",
        "            save_name = save_name.format(\n",
        "                epoch=self.epoch,\n",
        "                val_loss=self.val_loss,\n",
        "                val_acc=self.val_acc,\n",
        "                loss=self.loss,\n",
        "                acc=self.acc)\n",
        "            torch.save(ckpt, save_name)\n",
        "\n",
        "            # Reset epochs_since_ckpt counter\n",
        "            self.epochs_since_ckpt = 0\n",
        "\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "\n",
        "    def fit(self, X_train, y_train, X_val, y_val, epochs, lr, optimizer, criterion, save_name, monitor='val_loss', save_every=50, patience=3, save_best_only=True, regression=False):\n",
        "\n",
        "        assert monitor in ['val_acc', 'val_loss'], 'Not a suitable choice.'\n",
        "        assert os.path.exists(os.path.dirname(save_name)), \"Save directory doesn't exist\"\n",
        "\n",
        "        if monitor == 'val_loss':\n",
        "            self.compare_fn = lambda new: (new < np.array(self.deq)).any()\n",
        "        elif monitor == 'val_acc':\n",
        "            self.compare_fn = lambda new: (new > np.array(self.deq)).any()\n",
        "\n",
        "        # Define Loss, Optimizer\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer(self.parameters(), lr=lr)\n",
        "\n",
        "        # Initialize the Deque for checkpointing\n",
        "        self.deq = deque(maxlen=patience)\n",
        "\n",
        "        # Training\n",
        "        for epoch in range(1, epochs + 1):\n",
        "            self.epoch = epoch\n",
        "            self.optimizer.zero_grad()  # Clear existing gradient\n",
        "            output, hidden = self.__call__(X_train)\n",
        "            # print(output.shape)\n",
        "            loss = self.criterion(output.contiguous().view(output.shape[0], -1), y_train.contiguous().view(y_train.shape[0], -1))\n",
        "                # + self.step_loss(output.view(output.shape[0], -1), y_train)\n",
        "            self.loss = loss.item()\n",
        "            name, self.acc = self.accuracy(output, y_train) if not regression else self.step_loss(output, y_train)\n",
        "\n",
        "            # Evaluate on validation\n",
        "            with torch.no_grad():\n",
        "                output_val, _ = self.__call__(X_val)\n",
        "                self.val_loss = (self.criterion(output_val.contiguous().view(output_val.shape[0], -1), y_val.contiguous().view(y_val.shape[0], -1))).item()\n",
        "                        #  + self.step_loss(output_val.view(output_val.shape[0], -1), y_val.view(y_val.shape[0], -1))).item()\n",
        "                name, self.val_acc = self.accuracy(output_val, y_val) if not regression else self.step_loss(output_val, y_val)\n",
        "                # self.step_loss\n",
        "\n",
        "            # Append the metric value to queue\n",
        "            self.deq.append(eval('self.' + monitor))\n",
        "\n",
        "            # Check if it's been enough epochs since last checkpoint \n",
        "            if self.epochs_since_ckpt >= save_every:\n",
        "                self.checkpoint(eval('self.' + monitor), save_name, save_best_only)\n",
        "            else:\n",
        "                self.epochs_since_ckpt += 1\n",
        "\n",
        "            loss.backward()  # Does backprop and calculates grad\n",
        "            self.optimizer.step()  # Update the weights\n",
        "\n",
        "            print('\\rEpoch: {}/{}.............'.format(epoch, epochs), end=' ')\n",
        "            print(\"Loss: {:.4f} {name}: {:.4f}, Val_Loss: {:.4f} {name}: {:.4f}\".format(\n",
        "                self.loss, self.acc, self.val_loss, self.val_acc, name=name), end='')\n",
        "\n",
        "    def accuracy(self, y_pred, y_true, thresh=0.5):\n",
        "        \"\"\"Actually calculates F1 score.\"\"\"\n",
        "        # print(y_pred.shape)\n",
        "        # print(y_true.shape)\n",
        "\n",
        "        y_p = y_pred.detach().cpu().clone().numpy()\n",
        "        y_t = y_true.detach().cpu().clone().numpy()\n",
        "        # print(type(y_p))\n",
        "        return 'F1 Score', f1_score(y_t.flatten(), (y_p >= thresh).flatten())\n",
        "\n",
        "    def step_loss(self, y_pred, y_true):\n",
        "        \"\"\"Calculates MSE between calculated and actual no. of steps\"\"\"\n",
        "        # s_true = torch.sum(y_true, dim=1)\n",
        "        # s_pred = torch.sum(y_pred.round(), dim=1)\n",
        "        y_p = y_pred.detach().cpu().clone()\n",
        "        y_t = y_true.detach().cpu().clone()\n",
        "        return 'Step Loss', self.mse(y_p, y_t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Wk1UuLaJHbq",
        "colab_type": "text"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T87Dh0hDN41g",
        "colab_type": "text"
      },
      "source": [
        "## Vanilla RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njCi9cl_KkmJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(Master):\n",
        "    def __init__(self, input_size, output_size, seq_len, hidden_dim, n_cells, n_fc, fc_act=nn.ReLU(), regression=False):\n",
        "        \"\"\"\n",
        "        Model(input_size, output_size, hidden_dim, n_rnn, n_fc)\n",
        "        -------------------------------------------------------\n",
        "        <TODO>\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_size: int, required\n",
        "            No. of features per timestep in the input.\n",
        "        output_size: int, required\n",
        "            No. of samples in the output\n",
        "        hidden_dim: int, required\n",
        "            No. of nodes in the hidden layer of RNN\n",
        "        n_cells: int, required\n",
        "            No. of consecutive RNN units to stack\n",
        "        n_fc: list, required\n",
        "            A list of integers with no. of nodes to add in each FC layer.\n",
        "\n",
        "        \"\"\"\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        assert isinstance(n_fc, Iterable) and len(n_fc) >= 1,\\\n",
        "             \"Must be an iterable with length greater than or equal to 1\"\n",
        "        # Needed for parent class\n",
        "        self.init_args = (input_size, output_size, seq_len, hidden_dim, n_cells, n_fc, fc_act, regression)\n",
        "        self.deq = None\n",
        "        \n",
        "        self.hidden = None\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_cells = n_cells\n",
        "        self.regression = regression\n",
        "\n",
        "        # RNN Architecture\n",
        "        self.rnn = nn.RNN(input_size, hidden_dim, n_cells, batch_first=True, nonlinearity='tanh')\n",
        "        self.flatten = Flatten()\n",
        "\n",
        "        # FC Layers\n",
        "        self.fc = []\n",
        "        last_dim = seq_len * hidden_dim\n",
        "        for n_dims in n_fc:\n",
        "            self.fc.append(nn.Linear(last_dim, n_dims))\n",
        "            last_dim = n_dims\n",
        "\n",
        "        self.fc = nn.ModuleList(self.fc)  # Required to run on CUDA\n",
        "        self.fc_act = fc_act\n",
        "        self.out_fc = nn.Linear(n_fc[-1], output_size)\n",
        "        self.act = nn.functional.tanh\n",
        "\n",
        "    def forward(self, x):\n",
        "        # batch_size = x.size(0)\n",
        "        # print(x.shape)\n",
        "        # Initialize hidden state for first input\n",
        "        # if self.hidden is None:\n",
        "        #     hidden = self.init_hidden(batch_size)\n",
        "        # else:\n",
        "        #     hidden = self.hidden\n",
        "\n",
        "        # Passing into RNN\n",
        "        \n",
        "        out, hidden = self.rnn(x)  #, self.hidden)\n",
        "        out = self.flatten(out)\n",
        "        # print(out.shape)\n",
        "        for fc in self.fc:\n",
        "            out = fc(out)\n",
        "            out = self.fc_act(out)\n",
        "\n",
        "        out = self.out_fc(out)\n",
        "        if not self.regression:\n",
        "            out = (self.act(out) + 1) / 2\n",
        "        # self.hidden = hidden\n",
        "        return out, hidden\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzg_-KvhYDZT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54Lt_YdXaCLf",
        "colab_type": "text"
      },
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vxc38p_naDiP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# class Model(Master):\n",
        "#     def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
        "#         super(Model, self).__init__()\n",
        "\n",
        "#         # Needed for parent class\n",
        "#         self.init_args = (input_size, output_size, hidden_dim, n_layers)\n",
        "#         self.deq = None\n",
        "        \n",
        "#         self.hidden = None\n",
        "#         self.hidden_dim = hidden_dim\n",
        "#         self.n_layers = n_layers\n",
        "\n",
        "#         # RNN Architecture\n",
        "#         self.lstm = nn.LSTM(input_size, hidden_dim, n_layers, batch_first=True)\n",
        "#         self.fc = nn.Linear(hidden_dim, output_size)\n",
        "#         self.act = nn.functional.tanh\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         # batch_size = x.size(0)\n",
        "#         print(x.shape)\n",
        "#         # Initialize hidden state for first input\n",
        "#         # if self.hidden is None:\n",
        "#         #     hidden = self.init_hidden(batch_size)\n",
        "#         # else:\n",
        "#         #     hidden = self.hidden\n",
        "\n",
        "#         # Passing into RNN\n",
        "        \n",
        "#         out, hidden = self.lstm(x)  #, self.hidden)\n",
        "#         out = self.fc(out[:, -1, :])\n",
        "#         out = self.act(out)\n",
        "#         # self.hidden = hidden\n",
        "#         return out, hidden\n",
        "\n",
        "\n",
        "class Model(Master):\n",
        "    def __init__(self, input_size, output_size, seq_len, hidden_dim, n_cells, n_fc, fc_act=nn.ReLU(), regression=False):\n",
        "        \"\"\"\n",
        "        Model(input_size, output_size, hidden_dim, n_rnn, n_fc)\n",
        "        -------------------------------------------------------\n",
        "        <TODO>\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_size: int, required\n",
        "            No. of features per timestep in the input.\n",
        "        output_size: int, required\n",
        "            No. of samples in the output\n",
        "        hidden_dim: int, required\n",
        "            No. of nodes in the hidden layer of RNN\n",
        "        n_cells: int, required\n",
        "            No. of consecutive LSTM units to stack\n",
        "        n_fc: list, required\n",
        "            A list of integers with no. of nodes to add in each FC layer.\n",
        "\n",
        "        \"\"\"\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        assert isinstance(n_fc, Iterable) and len(n_fc) >= 1,\\\n",
        "             \"Must be an iterable with length greater than or equal to 1\"\n",
        "        # Needed for parent class\n",
        "        self.init_args = (input_size, output_size, seq_len, hidden_dim, n_cells, n_fc, fc_act, regression)\n",
        "        self.deq = None\n",
        "        \n",
        "        self.hidden = None\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_cells = n_cells\n",
        "        self.regression = regression\n",
        "\n",
        "        # RNN Architecture\n",
        "        self.lstm = nn.LSTM(input_size, hidden_dim, n_cells, batch_first=True) #, nonlinearity='tanh')\n",
        "        self.flatten = Flatten()\n",
        "\n",
        "        # FC Layers\n",
        "        self.fc = []\n",
        "        last_dim = seq_len * hidden_dim\n",
        "        for n_dims in n_fc:\n",
        "            self.fc.append(nn.Linear(last_dim, n_dims))\n",
        "            last_dim = n_dims\n",
        "\n",
        "        self.fc = nn.ModuleList(self.fc)  # Required to run on CUDA\n",
        "        self.fc_act = fc_act\n",
        "        self.out_fc = nn.Linear(n_fc[-1], output_size)\n",
        "        self.act = nn.functional.tanh\n",
        "\n",
        "    def forward(self, x):\n",
        "        # batch_size = x.size(0)\n",
        "        # print(x.shape)\n",
        "        # Initialize hidden state for first input\n",
        "        # if self.hidden is None:\n",
        "        #     hidden = self.init_hidden(batch_size)\n",
        "        # else:\n",
        "        #     hidden = self.hidden\n",
        "\n",
        "        # Passing into RNN\n",
        "        \n",
        "        out, hidden = self.lstm(x)  #, self.hidden)\n",
        "        out = self.flatten(out)\n",
        "        # print(out.shape)\n",
        "        for fc in self.fc:\n",
        "            out = fc(out)\n",
        "            out = self.fc_act(out)\n",
        "\n",
        "        out = self.out_fc(out)\n",
        "        if not self.regression:\n",
        "            out = (self.act(out))  # + 1) / 2\n",
        "        # self.hidden = hidden\n",
        "\n",
        "        return out, hidden\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hmg8LBX-DkYE",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qeqK0DSSCBkL",
        "colab": {}
      },
      "source": [
        "regression = True  #@param {type: \"boolean\"}\n",
        "hidden_dim = 20  #@param {type: \"integer\"}\n",
        "n_cells = 20  #@param {type: \"integer\"}\n",
        "n_fc = [20, 30]  #@param {type:\"raw\"}\n",
        "# fc_act = nn.functional.tanh\n",
        "fc_act = torch.tanh\n",
        "\n",
        "model = Model(\n",
        "    input_size=input_size,\n",
        "    output_size=window if not regression else 1,\n",
        "    seq_len=window,\n",
        "    hidden_dim=hidden_dim,\n",
        "    n_cells=n_cells,\n",
        "    n_fc=n_fc,\n",
        "    fc_act = fc_act,\n",
        "    regression=True\n",
        "    )\n",
        "\n",
        "model = model.to(device)\n",
        "# model.apply(weights_init)\n",
        "# summary(model, (window, input_size))\n",
        "\n",
        "if not regression:\n",
        "    # criterion = nn.BCELoss()\n",
        "    # criterion = weighted_binary_cross_entropy\n",
        "    criterion = f1_loss\n",
        "else:\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "optimizer = torch.optim.Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ed_81Alxehf3",
        "colab_type": "code",
        "outputId": "beaa89f1-1a36-4108-cead-cb477c13b86f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        }
      },
      "source": [
        "#@title Set training parameters\n",
        "epochs = 200 #@param\n",
        "lr = 1e-3 #@param\n",
        "models_dir = '/gdrive/My Drive/Step-Counting/RNN/' #@param\n",
        "model_name = 'Model.LSTM-regression_quat_features_only-train_acc={acc}-val_acc={val_acc}-Epoch-{epoch}.pth' #@param\n",
        "save_name = os.path.join(models_dir, model_name)\n",
        "if regression:\n",
        "    save_name = save_name.replace('acc', 'loss')\n",
        "\n",
        "\n",
        "model.fit(\n",
        "    X_train, y_train if not regression else torch.sum(y_train, dim=1).view([len(y_train), 1]),\n",
        "    X_val, y_val if not regression else torch.sum(y_val, dim=1).view([len(y_val), 1]),\n",
        "    epochs, lr,\n",
        "    optimizer,\n",
        "    criterion,\n",
        "    save_name=save_name,\n",
        "    regression=regression,\n",
        "    patience=100\n",
        "    )"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 50/200............. Loss: 21.6477 Step Loss: 21.6477, Val_Loss: 21.1163 Step Loss: 21.1163"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type Model. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type Flatten. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 184/200............. Loss: 17.7936 Step Loss: 17.7936, Val_Loss: 18.0415 Step Loss: 18.0415"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-db9f526bddbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0msave_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mregression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     )\n",
            "\u001b[0;32m<ipython-input-7-df9162d086ce>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, y_train, X_val, y_val, epochs, lr, optimizer, criterion, save_name, monitor, save_every, patience, save_best_only, regression)\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;31m# Evaluate on validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m                 \u001b[0moutput_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                         \u001b[0;31m#  + self.step_loss(output_val.view(output_val.shape[0], -1), y_val.view(y_val.shape[0], -1))).item()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-b7862db53c55>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# Passing into RNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#, self.hidden)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m# print(out.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_packed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_tensor\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0munsorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_impl\u001b[0;34m(self, input, hx, batch_sizes, max_batch_size, sorted_indices)\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             result = _VF.lstm(input, hx, self._get_flat_weights(), self.bias, self.num_layers,\n\u001b[0;32m--> 522\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    523\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._get_flat_weights(), self.bias,\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWA5w_CGy9Ca",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "69e1659e-172d-4c17-d810-579d78962284"
      },
      "source": [
        "print(model(X_val[0:1])[0])\n",
        "print(torch.sum(y_val[0:1], dim=1))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[4.5331]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([10.], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Mc8AH2lHKW3",
        "colab_type": "text"
      },
      "source": [
        "## Fastai"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tF1rgvKIHJ0V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.basic_train import Learner\n",
        "from fastai.basic_data import Dataset, DataBunch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHIfYTGOLMIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ArrayDataset(Dataset):\n",
        "    \"Sample numpy array dataset\"\n",
        "    def __init__(self, x, y):\n",
        "        self.x, self.y = x, y\n",
        "        self.c = 1 # binary label\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        return self.x[i], self.y[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRcOj832LMEm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X[:int(split * n), ...].astype(np.float32)\n",
        "y_train = y[:int(split * n), ...].astype(np.float32)\n",
        "X_val = X[int(split * n):, ...].astype(np.float32)\n",
        "y_val = y[int(split * n):, ...].astype(np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3y53qQzLLXf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, val = ArrayDataset(X_train, y_train), ArrayDataset(X_val, y_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgcihZN4JoY9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = DataBunch.create(train, val, bs=1, num_workers=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HvwzqcpJoP5",
        "colab_type": "code",
        "outputId": "ae1e2b03-3516-46f2-cb31-4940b89678e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "learn = Learner(data, Model, )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 76])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysMQLDDMKlMf",
        "colab_type": "text"
      },
      "source": [
        "# Scratchpad"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHheyzbgtw62",
        "colab_type": "code",
        "outputId": "702d553c-6dd9-4158-d032-c18ec523057d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "regression = True  #@param {type: \"boolean\"}\n",
        "hidden_dim = 40  #@param {type: \"integer\"}\n",
        "n_rnn = 20  #@param {type: \"integer\"}\n",
        "n_fc = [40, 20, 10, 5]  #@param {type:\"raw\"}\n",
        "# fc_act = nn.functional.tanh\n",
        "fc_act = torch.tanh\n",
        "\n",
        "model = Model(\n",
        "    input_size=input_size,\n",
        "    output_size=window if not regression else 1,\n",
        "    hidden_dim=hidden_dim,\n",
        "    n_rnn=n_rnn,\n",
        "    n_fc=n_fc,\n",
        "    fc_act = fc_act\n",
        "    )\n",
        "\n",
        "model = model.to(device)\n",
        "# model.apply(weights_init)\n",
        "summary(model, (window, input_size))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "               RNN-1  [[-1, 76, 40], [-1, 2, 40]]               0\n",
            "           Flatten-2                 [-1, 3040]               0\n",
            "            Linear-3                   [-1, 40]         121,640\n",
            "            Linear-4                   [-1, 20]             820\n",
            "            Linear-5                   [-1, 10]             210\n",
            "            Linear-6                    [-1, 5]              55\n",
            "            Linear-7                    [-1, 1]               6\n",
            "================================================================\n",
            "Total params: 122,731\n",
            "Trainable params: 122,731\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.83\n",
            "Params size (MB): 0.47\n",
            "Estimated Total Size (MB): 2.30\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1374: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqdfkHo5wbeV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import pickle\n",
        "loaded = torch.load('/gdrive/My Drive/Step-Counting/RNN/models/Model.RNN-regression.Epoch262-train_acc=29.385305404663086-val_acc=33.1422004699707.pth')\n",
        "# model.load_state_dict()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suY9shoFw7hM",
        "colab_type": "code",
        "outputId": "2e10288a-27e7-4ff6-e918-cabc72c49003",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "model = loaded['model']\n",
        "model.load_state_dict(loaded['state_dict'])\n",
        "for p in model.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "model.eval()\n",
        "model.to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (mse): MSELoss()\n",
              "  (rnn): RNN(13, 40, num_layers=20, batch_first=True)\n",
              "  (flatten): Flatten()\n",
              "  (fc): ModuleList(\n",
              "    (0): Linear(in_features=3040, out_features=40, bias=True)\n",
              "    (1): Linear(in_features=40, out_features=20, bias=True)\n",
              "    (2): Linear(in_features=20, out_features=10, bias=True)\n",
              "    (3): Linear(in_features=10, out_features=5, bias=True)\n",
              "  )\n",
              "  (fc_act): ReLU()\n",
              "  (out_fc): Linear(in_features=5, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwHxgMVZxmXh",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "4d9591c6-ebc5-49ca-bbed-ec6cff7f92b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "#@title Default title text\n",
        "i = 695 #@param {type:\"slider\", min:0, max:1000, step:1}\n",
        "\n",
        "print(model(X_train[i][None, ...])[0])\n",
        "print(y_train[i].sum())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1.]], device='cuda:0')\n",
            "tensor(0., device='cuda:0')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1374: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Esp93WWEvkf",
        "colab_type": "text"
      },
      "source": [
        "## Basic RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcgolMA1JIWA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # text = ['hey how are you','good i am fine','have a nice day']\n",
        "# chars = set(''.join(text))\n",
        "# int2char = dict(enumerate(chars))\n",
        "# char2int = {char: ind for ind, char in int2char.items()}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zreFuiSZKyEv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Finding the length of the longest string in our data\n",
        "# maxlen = len(max(text, key=len))\n",
        "\n",
        "# # Padding\n",
        "\n",
        "# # A simple loop that loops through the list of sentences and adds a ' ' whitespace until the length of\n",
        "# # the sentence matches the length of the longest sentence\n",
        "# for i in range(len(text)):\n",
        "#   while len(text[i])<maxlen:\n",
        "#       text[i] += ' '"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHBtZTHHSMDh",
        "colab_type": "code",
        "outputId": "3d77850b-8468-48ca-845a-6f3caefe9d87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# # Creating lists that will hold our input and target sequences\n",
        "# input_seq = []\n",
        "# target_seq = []\n",
        "\n",
        "# for i in range(len(text)):\n",
        "#     # Remove last character for input sequence\n",
        "#     input_seq.append(text[i][:-1])\n",
        "\n",
        "#     # Remove first character for target sequence\n",
        "#     target_seq.append(text[i][1:])\n",
        "#     print(\"Input Sequence: {}\\nTarget Sequence: {}\".format(input_seq[i], target_seq[i]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Sequence: hey how are yo\n",
            "Target Sequence: ey how are you\n",
            "Input Sequence: good i am fine\n",
            "Target Sequence: ood i am fine \n",
            "Input Sequence: have a nice da\n",
            "Target Sequence: ave a nice day\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-RVwCdqSbxM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for i in range(len(text)):\n",
        "#     input_seq[i] = [char2int[character] for character in input_seq[i]]\n",
        "#     target_seq[i] = [char2int[character] for character in target_seq[i]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0KyEEWYXyyE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dict_size = len(char2int)\n",
        "# seq_len = maxlen - 1\n",
        "# batch_size = len(text)\n",
        "\n",
        "# def one_hot_encode(sequence, dict_size, seq_len, batch_size):\n",
        "#     # Creating a multi-dimensional array of zeros with the desired output shape\n",
        "#     features = np.zeros((batch_size, seq_len, dict_size), dtype=np.float32)\n",
        "    \n",
        "#     # Replacing the 0 at the relevant character index with a 1 to represent that character\n",
        "#     for i in range(batch_size):\n",
        "#         for u in range(seq_len):\n",
        "#             features[i, u, sequence[i][u]] = 1\n",
        "#     return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zujfj43Zz-7n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# input_seq = one_hot_encode(input_seq, dict_size, seq_len, batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zfple8zPz-x5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# input_seq = torch.from_numpy(input_seq)\n",
        "# target_seq = torch.Tensor(target_seq)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GbTUsFN8RbI",
        "colab_type": "code",
        "outputId": "dbcedfc9-2a78-41a8-c581-0d7772a3ea93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# input_seq.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 14, 17)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4EWsXcw8a6s",
        "colab_type": "code",
        "outputId": "d3c614b1-8101-4fed-e69f-6b9cabe801de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# len(target_seq[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmT2lBsv0FHX",
        "colab_type": "code",
        "outputId": "cb809db7-45f2-4ade-9498-5e31a41e3dfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# # torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
        "# is_cuda = torch.cuda.is_available()\n",
        "\n",
        "# # If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
        "# if is_cuda:\n",
        "#     device = torch.device(\"cuda\")\n",
        "#     print(\"GPU is available\")\n",
        "# else:\n",
        "#     device = torch.device(\"cpu\")\n",
        "#     print(\"GPU not available, CPU used\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU is available\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYO_Cabv0FEk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# class Model(nn.Module):\n",
        "#     def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
        "#         super(Model, self).__init__()\n",
        "#         self.hidden_dim = hidden_dim\n",
        "#         self.n_layers = n_layers\n",
        "\n",
        "#         # RNN Architecture\n",
        "#         self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)\n",
        "#         self.fc = nn.Linear(hidden_dim, output_size)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         batch_size = x.size(0)\n",
        "\n",
        "#         # Initialize hiddedn state for first input\n",
        "#         hidden = self.init_hidden(batch_size)\n",
        "\n",
        "#         # Passing into RNN\n",
        "#         out, hidden = self.rnn(x, hidden)\n",
        "        \n",
        "#         # Reshape and pass on to FC layer\n",
        "#         out = out.contiguous().view(-1, self.hidden_dim)\n",
        "#         out = self.fc(out)\n",
        "\n",
        "#         return out, hidden\n",
        "\n",
        "#     def init_hidden(self, batch_size):\n",
        "#         # Passing a tensor of zeros as the intial input, always.\n",
        "#         hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim, device=device)\n",
        "#         return hidden\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzxIVlCH0E0A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model = Model(input_size=dict_size, output_size=dict_size, hidden_dim=12, n_layers=1)\n",
        "# model = model.to(device)\n",
        "\n",
        "# # Define Hyperparameters\n",
        "# n_epochs = 100\n",
        "# lr = 0.01\n",
        "\n",
        "# # Define Loss, Optimizer\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjVmasIX5ton",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Training\n",
        "# target_seq = target_seq.to(device)\n",
        "# for epoch in range(1, n_epochs + 1):\n",
        "#     optimizer.zero_grad()  # Clear existing gradient\n",
        "#     input_seq = input_seq.to(device)\n",
        "#     output, hidden = model(input_seq)\n",
        "#     loss = criterion(output, target_seq.view(-1).long())\n",
        "#     loss.backward()  # Does backprop and calculates grad\n",
        "#     optimizer.step()  # Update the weights\n",
        "\n",
        "#     if epoch%10 == 0:\n",
        "#         print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
        "#         print(\"Loss: {:.4f}\".format(loss.item()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gasf7MweEzSX",
        "colab_type": "text"
      },
      "source": [
        "## Something Else"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AekZ-WivFHJa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# rnn = nn.LSTM(input_size=13, hidden_size=10, num_layers=5, batch_first=True, )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsT7VEUhFHEE",
        "colab_type": "code",
        "outputId": "e5e4be55-a16a-471c-f83c-fed761d5c301",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# inp = torch.from_numpy(np.zeros((10, 76, 13), dtype=float)).to(torch.float)\n",
        "# inp.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 76, 13])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIWXDM7uFG_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# out, hidden = rnn(inp, None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4t4rNRb1giW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "outputId": "a6bd7086-964c-43a1-cbfa-6fae90776f44"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from scipy.ndimage import zoom\n",
        "i = 16\n",
        "img = X[i]\n",
        "# img = cv2.resize(img, (76, 30))\n",
        "img = zoom(img, (1, 5))\n",
        "print(img.shape)\n",
        "img[y[i] == 1, :] = 255\n",
        "plt.imshow(img)\n",
        "# plt.plot(y[1])\n",
        "# X[0:8].shape"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(76, 50)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f1884093a20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAALQAAAD8CAYAAADexo4zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMwDmBV_4FYO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bba1711f-cb49-4e47-d040-14a467ce26dd"
      },
      "source": [
        "y[10].sum()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    }
  ]
}